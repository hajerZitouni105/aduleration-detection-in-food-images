{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Anomaly Detection:<br> Spinach Adulterated Pistachios***\n",
    "\n",
    "---\n",
    "\n",
    "# TODO: USE LOADIMAGESFROMDATASET MTA3 L KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les pistaches adultérées avec des épinards posent un problème de sécurité alimentaire. Cette fraude consiste à mélanger des feuilles d'épinards avec des pistaches pour augmenter le poids du produit et réaliser des profits illégaux. <br>Les consommateurs obtiennent un produit de qualité inférieure et potentiellement dangereux, pouvant contenir des contaminants ou des allergènes. <br>Les autorités sanitaires et les organismes de contrôle travaillent pour détecter et prévenir cette fraude, protégeant ainsi les consommateurs et la chaîne d'approvisionnement alimentaire. Pour attaquer ce problème, nous utiliserons un autoencodeur qui détectera ce type de fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Définir les paramètres de prétraitement des images\n",
    "batch_size = 32\n",
    "image_size = (64, 64)\n",
    "\n",
    "# Fonction pour charger et prétraiter les images\n",
    "def load_images_from_folder(folder, target_size=(64, 64)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = load_img(os.path.join(folder, filename), target_size=target_size)\n",
    "        img_array = img_to_array(img) / 255.0  # Normalisation des valeurs des pixels\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# Charger les images de pistaches pures\n",
    "pure_pistachios_folder = './dataset/pure/Pure Pistachios'\n",
    "pure_pistachios = load_images_from_folder(pure_pistachios_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Définir l'architecture du modèle\n",
    "input_img = layers.Input(shape=(64, 64, 3))\n",
    "\n",
    "# Encodeur\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Décodeur\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Créer le modèle\n",
    "autoencoder = models.Model(input_img, decoded)\n",
    "\n",
    "# Compiler le modèle\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Afficher un résumé de l'architecture du modèle\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Créer un générateur d'augmentation de données\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Prétraiter et augmenter les images\n",
    "augmented_pure_pistachios = []\n",
    "for batch in datagen.flow(pure_pistachios, batch_size=32):\n",
    "    augmented_pure_pistachios.extend(batch)\n",
    "    if len(augmented_pure_pistachios) >= len(pure_pistachios):\n",
    "        break\n",
    "\n",
    "# Convertir la liste en tableau numpy\n",
    "augmented_pure_pistachios = np.array(augmented_pure_pistachios)\n",
    "\n",
    "pure_pistachios_dataset_val = np.array(pure_pistachios_dataset_val)\n",
    "print(pure_pistachios_dataset_val.shape)\n",
    "\n",
    "# Entraîner l'autoencodeur sur les données augmentées\n",
    "autoencoder.fit(augmented_pure_pistachios, validation_data= pure_pistachios_dataset_val, epochs=30, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fonction pour détecter la fraude\n",
    "def detect_fraud(images, model, threshold=0.0038):\n",
    "    fraud_images = []\n",
    "    for img in images:\n",
    "        reconstructed_img = model.predict(np.expand_dims(img, axis=0))\n",
    "        reconstruction_error = np.mean((img - reconstructed_img[0]) ** 2)\n",
    "        print(reconstruction_error)\n",
    "        if reconstruction_error > threshold:\n",
    "            fraud_images.append(img)\n",
    "    return fraud_images\n",
    "\n",
    "# Charger les images adultérées et détecter la fraude\n",
    "# adulterated_pistachios_folder = './dataset/pure/Pure pistachios' # 0.0038 BEHI LEL PUR\n",
    "adulterated_pistachios_folder = './dataset/all_adulterated' \n",
    "\n",
    "adulterated_pistachios = load_images_from_folder(adulterated_pistachios_folder)\n",
    "fraudulent_images = detect_fraud(adulterated_pistachios, autoencoder)\n",
    "print(f\"Nombre d'images frauduleuses détectées : {len(fraudulent_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importation des Bibliothèques :**\n",
    "---\n",
    "Nous commençons par importer les bibliothèques nécessaires pour ce projet. TensorFlow sera utilisé pour construire et entraîner notre modèle de réseau de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Définition des Paramètres :**\n",
    "---\n",
    "Nous définissons les paramètres de notre projet, notamment le chemin vers notre dataset, la taille des lots, et les dimensions des images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le répertoire parent contenant les sous-dossiers\n",
    "dataset_dir = './dataset'\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Chargement des données :**\n",
    "---\n",
    "Nous utilisons `image_dataset_from_directory` pour charger nos images depuis les sous-dossiers. Cette fonction divise automatiquement les données en ensembles d'entraînement et de validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Structure de notre dataset :**\n",
    "dataset/ <br>\n",
    "├── 10% spinach adulterated pistachios/ <br>\n",
    "├── 20% spinach adulterated pistachios/ <br>\n",
    "├── 30% spinach adulterated pistachios/ <br> \n",
    "├── 40% spinach adulterated pistachios/ <br>\n",
    "├── 50% spinach adulterated pistachios/ <br>\n",
    "└── Pure pistachios/ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des datasets d'entraînement \n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',  # Classification multiclasses\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des datasets de validation\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',  # Classification multiclasses\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Normalisation des images:**\n",
    "---\n",
    " Nous normalisons les images pour que les valeurs des pixels soient comprises entre 0 et 1, ce qui facilite l'entraînement du modèle.\n",
    "\n",
    "La normalisation des données dans le cadre d'un autoencodeur est essentielle pour plusieurs raisons. \n",
    "\n",
    "D'une part, elle rend les données comparables et cohérentes, facilitant ainsi le processus d'apprentissage en ramenant les valeurs à une échelle commune.\n",
    "\n",
    "D'autre part, elle évite que certaines caractéristiques ne dominent le processus d'apprentissage, en assurant une contribution équilibrée de chaque caractéristique à la représentation latente apprise par l'autoencodeur. \n",
    "\n",
    "Donc, la normalisation des données favorise un meilleur apprentissage et des représentations latentes plus robustes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des images\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "normalized_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Définition du Modèle :**\n",
    "---\n",
    "Nous définissons un modèle de réseau de neurones convolutionnel (CNN) pour la classification d'images. Ce modèle comprend plusieurs couches convolutives et de pooling, suivies de couches denses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle de classification\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "print('Classes :', train_ds.class_names)\n",
    "print('Nombre de classes :', num_classes)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Multiclasses\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Compilation du Modèle :**\n",
    "---\n",
    "Nous compilons le modèle en utilisant l'optimiseur Adam et la perte `SparseCategoricalCrossentropy`, qui est adaptée pour la classification multiclasses.<br>\n",
    "Nous affichons le résumé du modèle pour visualiser les différentes couches et le nombre de paramètres entraînables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='model_schema.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Entraînement du Modèle :**\n",
    "Nous entraînons le modèle sur notre dataset d'entraînement et évaluons ses performances sur le dataset de validation. Le nombre d'époques d'entraînement est fixé à 50.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "history = model.fit(\n",
    "    normalized_train_ds,\n",
    "    validation_data=normalized_val_ds,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Évaluation du Modèle :**\n",
    "---\n",
    "Nous évaluons les performances du modèle sur le dataset de validation pour obtenir la précision finale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(normalized_val_ds)\n",
    "print(f'Validation accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Prédiction avec le Modèle :**\n",
    "---\n",
    "Nous définissons une fonction de prédiction qui prend en entrée une image, la prétraite et utilise le modèle pour prédire sa classe. Un exemple de prédiction est fourni.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Faire des prédictions\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "def predict(model, img_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions)]\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemple de prédiction\n",
    "img_path = 'dataset/pure/Pure pistachios/IMG_2203.JPG'\n",
    "predicted_class = predict(model, img_path)\n",
    "print(f'The predicted class is: {predicted_class}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chemin vers le répertoire parent contenant les sous-dossiers\n",
    "dataset_dir = './dataset'\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chargement des datasets d'entraînement et de validation\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',  # Classification binaire\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',  # Classification binaire\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalisation des images\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "normalized_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définition de l'autoencodeur\n",
    "input_img = layers.Input(shape=(img_height, img_width, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encoder\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Decoder\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autoencoder = models.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage des images pures pour l'entraînement de l'autoencodeur\n",
    "pure_pistachios_ds = normalized_train_ds.filter(lambda x, y: tf.equal(y, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entraînement de l'autoencodeur\n",
    "autoencoder.fit(\n",
    "    pure_pistachios_ds,\n",
    "    epochs=10,\n",
    "    validation_data=normalized_val_ds\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Détection des anomalies\n",
    "def calculate_reconstruction_error(original, reconstructed):\n",
    "    return np.mean(np.abs(original - reconstructed), axis=(1, 2, 3))\n",
    "\n",
    "threshold = 0.02  # Ce seuil doit être déterminé empiriquement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_anomalies(autoencoder, dataset):\n",
    "    anomalies = []\n",
    "    for images, labels in dataset:\n",
    "        reconstructed = autoencoder.predict(images)\n",
    "        errors = calculate_reconstruction_error(images.numpy(), reconstructed)\n",
    "        anomalies.extend(errors > threshold)\n",
    "    return anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anomalies_train = detect_anomalies(autoencoder, normalized_train_ds)\n",
    "anomalies_val = detect_anomalies(autoencoder, normalized_val_ds)\n",
    "\n",
    "print(f\"Anomalies in training set: {np.sum(anomalies_train)}\")\n",
    "print(f\"Anomalies in validation set: {np.sum(anomalies_val)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
